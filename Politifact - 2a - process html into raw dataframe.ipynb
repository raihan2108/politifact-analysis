{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis ideas\n",
    "* word cloud or analysis of what words are indicative of lying or truth\n",
    "* ranking of who is most trustworthy and liars\n",
    "* compare republicans and democrats based on their personalities bio page text\n",
    "    * e.g. https://www.politifact.com/personalities/seth-moulton/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of reading 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/scott/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Load a saved html\n",
    "file = open('/gh/data/politifact/20190701scrape/{}.html'.format(3),'r') \n",
    "html = file.read()\n",
    "\n",
    "# Get list of html for each entry\n",
    "bsObj = BeautifulSoup(html)\n",
    "record_list = bsObj.findAll(\"div\", {'class': 'scoretable__item'})\n",
    "\n",
    "# 1. name\n",
    "name = nameList[0].find(\"div\", {'class': 'statement__source'}).text.strip()\n",
    "\n",
    "# 2. statement\n",
    "statement = nameList[0].find(\"div\", {'class': 'statement__body'}) \\\n",
    "                       .find(\"p\", {'class': 'statement__text'}) \\\n",
    "                       .find(\"a\", {'class': 'link'}).text.strip()\n",
    "           \n",
    "# 3. source\n",
    "source = nameList[0].find(\"p\", {'class': 'statement__edition'}).find('a').text.strip()\n",
    "\n",
    "# 4. date\n",
    "date = nameList[0].find(\"span\", {'class': 'article__meta'}).text.strip()\n",
    "\n",
    "# 5. conclusion\n",
    "finding = nameList[0].find(\"div\", {'class': 'meter'}).find('img')['alt'].strip()\n",
    "\n",
    "# 6. comment\n",
    "comment = nameList[0].find('p', {'class': 'quote'}).text.strip()\n",
    "\n",
    "personalities_page = nameList[0].find('div', {'class': 'statement__source'}).find('a')['href'].strip()\n",
    "\n",
    "article_page = nameList[0].find('p', {'class': 'statement__text'}).find('a')['href'].strip()\n",
    "\n",
    "print(name)\n",
    "print(statement)\n",
    "print(source)\n",
    "print(date)\n",
    "print(finding)\n",
    "print(comment)\n",
    "print(personalities_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all htmls into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/scott/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Make table of raw strings for each category\n",
    "dfs = []\n",
    "\n",
    "# Load and process data for each page\n",
    "for page_number in range(1, 813):\n",
    "    # Load a saved html\n",
    "    file = open('/gh/data/politifact/20190701scrape/{}.html'.format(page_number),'r') \n",
    "    html = file.read()\n",
    "\n",
    "    # Get list of html for each entry\n",
    "    bsObj = BeautifulSoup(html)\n",
    "    record_list = bsObj.findAll(\"div\", {'class': 'scoretable__item'})\n",
    "\n",
    "    dict_data = defaultdict(list)\n",
    "    for record_html in record_list:\n",
    "        # Parse html and add content for each bit of information\n",
    "        dict_data['name'].append(record_html.find(\"div\", {'class': 'statement__source'}).text.strip())\n",
    "        dict_data['statement'].append(record_html.find(\"div\", {'class': 'statement__body'}) \\\n",
    "                           .find(\"p\", {'class': 'statement__text'}) \\\n",
    "                           .find(\"a\", {'class': 'link'}).text.strip())\n",
    "        dict_data['source'].append(record_html.find(\"p\", {'class': 'statement__edition'}).find('a').text.strip())\n",
    "        dict_data['date'].append(record_html.find(\"span\", {'class': 'article__meta'}).text.strip())\n",
    "        dict_data['finding'].append(record_html.find(\"div\", {'class': 'meter'}).find('img')['alt'].strip())\n",
    "        dict_data['comment'].append(record_html.find('p', {'class': 'quote'}).text.strip())\n",
    "        dict_data['personalities_page'].append(record_html.find('div', {'class': 'statement__source'}).find('a')['href'].strip())\n",
    "        dict_data['article_page'].append(record_html.find('p', {'class': 'statement__text'}).find('a')['href'].strip())\n",
    "    dfs.append(pd.DataFrame(dict_data))\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Save raw processed data\n",
    "# df.to_csv('/gh/data/politifact/20190701scrape/raw_processed.csv')\n",
    "df.to_csv('/gh/data/politifact/20190701scrape/raw_processed_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
